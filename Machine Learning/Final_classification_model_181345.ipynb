{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final classification model - 181345.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Lp71UwMuU1vs",
        "B3GoMu8gGaU8",
        "jJ8wNpmGmfKl",
        "KY0RrYIPB4hh",
        "jdtEwFOFx5p1",
        "DEPybzRQi0CG",
        "mQhLmfoUsr7w",
        "1YD8Yb6DtI5p",
        "P4CWfD86mTpG",
        "LGs6vQ5zx3NK",
        "BypOY-DtV-th",
        "ZY7QK1-_xoql",
        "zUgqhSN4P4zz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6RgrgFE8AxX",
        "colab_type": "text"
      },
      "source": [
        "## Primary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY5Uf14v8EUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Primary imports\n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "import pandas as pd \n",
        "from pprint import pprint\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# For data split \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Import Classifier SVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Random grid search\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Feature Selection\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from statistics import mean\n",
        "\n",
        "# Data undersampling\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Imports for Learning curve\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "# Google colab import file\n",
        "from google.colab import files\n",
        "\n",
        "# Validation curve\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import Ridge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFjHAr0oQVJ8",
        "colab_type": "text"
      },
      "source": [
        "# **SVC model using all CNN and GIST features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66hP1P0i8L22",
        "colab_type": "text"
      },
      "source": [
        "## **Loading training & test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2iQP-Tq8Hn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading and reading the training data\n",
        "training_data = pd.read_csv(\"training.csv\")\n",
        "# Loading and reading the testing data\n",
        "testing_data  = pd.read_csv(\"testing.csv\")\n",
        "# Loading and reading the additional training data\n",
        "additional_data = pd.read_csv(\"additional_training.csv\")\n",
        "# Loading the annotation confidence data\n",
        "annotation_data = pd.read_csv(\"annotation_confidence.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LnAttw38TB4",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing - Setting up the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQVuk2ED8JE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up the data\n",
        "df_train = training_data.values\n",
        "\n",
        "# Removing the titles and last column of the training data and assigning to X\n",
        "X = df_train[:, 1:-1]\n",
        "\n",
        "# Assigning y to the last column of the training data\n",
        "y = df_train[:, -1:]\n",
        "y = y.ravel()\n",
        "\n",
        "# Replacing the \"NaN\" values with the mean value of each column\n",
        "additional_data = additional_data.fillna(additional_data.mean())\n",
        "df_additional_data = additional_data.values\n",
        "ad = df_additional_data[:,1:-1]\n",
        "\n",
        "# Assigning ad_y to the last column of the additional training data\n",
        "ad_y = df_additional_data[:, -1:]\n",
        "ad_y = ad_y.ravel()\n",
        "\n",
        "# Testing values to generate the predictions\n",
        "df_test = testing_data.values\n",
        "testdata = df_test[:,1:]\n",
        "\n",
        "# Pre-processing the data to insert in fit\n",
        "df_annotation_confidence = annotation_data.values\n",
        "ac = df_annotation_confidence[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV5Nbz8Xbl-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate the training data and additional training data (NaN values contain the mean)\n",
        "# Concatenate the train X and additional train X\n",
        "X = np.concatenate((X,ad))\n",
        "# Concatenate the train y and additional train y\n",
        "y = np.concatenate((y,ad_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZo6ZK8N85AP",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf0iacxaj55r",
        "colab_type": "text"
      },
      "source": [
        "### **Normalization - most optimal**\n",
        "run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUPHnUvB893A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying standard normalization to get optimized results\n",
        "transformer = Normalizer().fit(X)\n",
        "# Normalizing the X data\n",
        "X = transformer.transform(X)\n",
        "# Normalizing the test data\n",
        "testdata = transformer.transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp71UwMuU1vs",
        "colab_type": "text"
      },
      "source": [
        "### Binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA46xz-EU1A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying binarization as an alternative preprocessing method\n",
        "# Binarize the X values\n",
        "X = preprocessing.Binarizer(threshold=0.6).transform(X)\n",
        "testdata = preprocessing.Binarizer(threshold=0.6).transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3GoMu8gGaU8",
        "colab_type": "text"
      },
      "source": [
        "### Min-Max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tyLqupDGZn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying MinMax scaling the data whilst preserving the shape of the original distribution. \n",
        "# It doesnâ€™t meaningfully change the information embedded in the original data.\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "testdata = scaler.transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ8wNpmGmfKl",
        "colab_type": "text"
      },
      "source": [
        "## **Standardization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz2TuLnxmeQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying standardization as a means of pre-processing.\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "testdata = scaler.fit_transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1dNvBQxY2KL",
        "colab_type": "text"
      },
      "source": [
        "## **Data undersampling - most optimal**\n",
        "run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6JsiaVwY1ve",
        "colab_type": "code",
        "outputId": "79ae3e2d-99f3-4b58-9152-35a5eb6e2654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Applying data undersampling to balance the train and test value split\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_res, y_res = rus.fit_resample(X, y)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n",
        "confidence_labels = []\n",
        "\n",
        "for index in rus.sample_indices_:\n",
        "  confidence_labels.extend(ac[index])\n",
        "confidence_values = np.asarray(confidence_labels, dtype = np.float32)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 1035, 1.0: 1035})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY0RrYIPB4hh",
        "colab_type": "text"
      },
      "source": [
        "## **Manual data undersampling** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDzL8deCNJBU",
        "colab_type": "code",
        "outputId": "b1129809-ef20-4f04-bdcd-6520cc76dfc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "count1 = 0\n",
        "count2 = 0\n",
        "ac_list = [] \n",
        "feature_list = []\n",
        "label_list = []\n",
        "for i,feature in enumerate(X):\n",
        "  if count1 < 1035 and y[i] == 1:\n",
        "    count1 = count1 + 1\n",
        "    ac_list.extend(ac[i])\n",
        "    label_list.append(y[i])\n",
        "    feature_list.append(feature)\n",
        "  if count2 < 1035 and y[i] == 0:\n",
        "    count2 = count2 + 1\n",
        "    ac_list.extend(ac[i])\n",
        "    label_list.append(y[i])\n",
        "    feature_list.append(feature)\n",
        "  if count1 + count2 == 2070:\n",
        "    break\n",
        "\n",
        "X = np.array(feature_list)\n",
        "y = label_list\n",
        "sample_weight = ac_list\n",
        "print(len(X))\n",
        "print(len(y))\n",
        "print(len(sample_weight))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2070\n",
            "2070\n",
            "2070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQoEPTx-odh",
        "colab_type": "text"
      },
      "source": [
        "## **Feature Selection - PCA - most optimal**\n",
        "run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmLuQNwA-VZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying principal component analysis (PCA) to reduce the dimensionality of the training data set consisting of\n",
        "# a variation of values.\n",
        "pca = PCA(n_components=0.86, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(X_res)\n",
        "X_res = pca.transform(X_res)\n",
        "testdata = pca.transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdtEwFOFx5p1",
        "colab_type": "text"
      },
      "source": [
        "# Grid search investigation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEPybzRQi0CG",
        "colab_type": "text"
      },
      "source": [
        "## **Feature Selection - PCA (Grid Search)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1__Uwpai-s9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying principal component analysis (PCA) to reduce the dimensionality of the training data set consisting of\n",
        "# a variation of values. Running additional grid search to find the optimal n_components value for PCA.\n",
        "pca_grid = PCA()\n",
        "param_grid = {'n_components' : np.linspace(0.1,0.9)}\n",
        "grid_search_pca = GridSearchCV(pca_grid,param_grid, cv = 5, n_jobs = -1, verbose = 10)\n",
        "grid_search_pca.fit(X_res,y_res.ravel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OgnbclH--hd",
        "colab_type": "code",
        "outputId": "6cbc06fb-2ebb-4c59-c6ad-7b7b95406386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(grid_search_pca.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_components': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQhLmfoUsr7w",
        "colab_type": "text"
      },
      "source": [
        "## **Examining the SVC to determine parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59FrfzsosrWZ",
        "colab_type": "code",
        "outputId": "e225d53b-9173-46e0-a38d-969ccf4269d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Examining the SVC default parameters for the different grid search methods\n",
        "svc = SVC(C = 1, kernel = 'rbf',random_state = 42)\n",
        "\n",
        "# Displaying the default parameters\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(svc.get_params())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'C': 1.0,\n",
            " 'cache_size': 200,\n",
            " 'class_weight': None,\n",
            " 'coef0': 0.0,\n",
            " 'decision_function_shape': 'ovr',\n",
            " 'degree': 3,\n",
            " 'gamma': 'auto_deprecated',\n",
            " 'kernel': 'rbf',\n",
            " 'max_iter': -1,\n",
            " 'probability': False,\n",
            " 'random_state': 42,\n",
            " 'shrinking': True,\n",
            " 'tol': 0.001,\n",
            " 'verbose': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YD8Yb6DtI5p",
        "colab_type": "text"
      },
      "source": [
        "## **Random Search with Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoeH0Ph_tNYJ",
        "colab_type": "code",
        "outputId": "f3b369e9-62ad-49bf-f270-312067772d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Running a Random grid search to optimize the hyperparameters\n",
        "# C values\n",
        "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "# Gamma values\n",
        "gamma = [0.001, 0.01, 0.1, 1, 5, 10, 100]\n",
        "# Kernel values\n",
        "kernel = ['rbf','linear']\n",
        "# Creating the random grid\n",
        "random_grid = {'C': C,'gamma': gammas,'kernel': kernel}\n",
        "pprint(random_grid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            " 'gamma': [0.001, 0.01, 0.1, 1, 5, 10, 100],\n",
            " 'kernel': ['rbf', 'linear']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paepHM9bur_n",
        "colab_type": "code",
        "outputId": "c420615c-02d6-40fa-fb9f-cf0e23a2aaa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# Using the random grid to search for best hyperparameters\n",
        "# Creating the base model to tune the model\n",
        "svc = SVC(random_state = 42)\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and using all available cores\n",
        "svc_random = RandomizedSearchCV(estimator=svc, param_distributions=random_grid,n_iter = 100, scoring='accuracy',cv = 5, verbose=10, random_state=42, n_jobs=-1,return_train_score=True)\n",
        "# Fit the random search model\n",
        "svc_random.fit(X_res, y_res);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 98 is smaller than n_iter=100. Running 98 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   28.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   41.4s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  9.9min\n",
            "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 10.7min\n",
            "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed: 11.6min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 12.5min\n",
            "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed: 13.4min\n",
            "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed: 14.3min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 15.3min\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed: 16.3min\n",
            "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=-1)]: Done 477 tasks      | elapsed: 22.1min\n",
            "[Parallel(n_jobs=-1)]: Done 490 out of 490 | elapsed: 23.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-by4j-2vrsU",
        "colab_type": "code",
        "outputId": "8634ff19-9087-4479-9d9b-1a2314855b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returning the best parameters\n",
        "svc_random.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'gamma': 0.001, 'kernel': 'linear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4CWfD86mTpG",
        "colab_type": "text"
      },
      "source": [
        "## **SVC Classifier - Grid Search**\n",
        "We can now perform grid search building on the result from the random search. We will test a range of hyperparameters around the best values returned by random search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hCAPIQow8Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the parameter grid based on the results of random search \n",
        "param_grid = {'C': [1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2],'gamma': [0.001, 0.0012,0.0013,0.0014,0.0015,0.0016],'kernel': ['linear']}\n",
        "# Creating a base model\n",
        "svc = SVC(random_state = 42)\n",
        "# Instantiate the grid search model\n",
        "grid_search_svc = GridSearchCV(estimator = svm.SVC(), param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 10,return_train_score=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqYade8Txe-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the grid search to the data\n",
        "grid_search_svc.fit(X_res, y_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYSxWQATxoPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returning the most optimial grid search\n",
        "grid_search_svc.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGs6vQ5zx3NK",
        "colab_type": "text"
      },
      "source": [
        "## **Additional grid search for maximal optmization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gQsTFYUx6HI",
        "colab_type": "code",
        "outputId": "4489232b-f946-4e5b-d4d4-e60a589e2723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {'C': [1.5,1.51,1.52,1.53,1.54,1.55,1.56,1.57,1.58,1.59,1.6],'gamma': [0.001,0.0011,0.00112,0.001123,0.0011234,0.00112345,0.00112345],'kernel': ['linear']}\n",
        "# Creating a base model\n",
        "svc = SVC(random_state = 42)\n",
        "# Instantiating the grid search model\n",
        "grid_search_svc_final = GridSearchCV(estimator = svm.SVC(), param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 10,return_train_score=True)\n",
        "grid_search_svc_final.fit(X_res, y_res);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 77 candidates, totalling 385 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   20.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   27.6s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   42.2s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   55.0s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  8.9min\n",
            "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=-1)]: Done 385 out of 385 | elapsed: 12.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Yly0Ngx-9g",
        "colab_type": "code",
        "outputId": "ca5f0433-5fac-45ba-f838-4c6d7e36656e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returning the most optimal parameters\n",
        "grid_search_svc_final.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.5, 'gamma': 0.001, 'kernel': 'linear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Y2rHaR_Gyg",
        "colab_type": "text"
      },
      "source": [
        "# **SVC Classifier - final model implementation**\n",
        "The final model with the hyperparameters returned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlXbGHzGaFNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d798e18b-9f8e-4902-cbdc-51b5d0f43dce"
      },
      "source": [
        "# Implementing the final SVC model with the optimal parameters\n",
        "# The values from the confidence values are passed into the sample weights\n",
        "#final_model = grid_search_svc.best_estimator_\n",
        "svc = SVC(C=1.5, kernel='linear', gamma=0.001)\n",
        "svc.fit(X_res,y_res,sample_weight = confidence_values)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.5, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQWMTv1zbF0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = svc.predict(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XUkAC3E8ZXI",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUBsac7K8YSw",
        "colab_type": "code",
        "outputId": "0aac452c-defe-4d49-f41b-45caeaa8d0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Returning the cross validation score using KFolds. \n",
        "scores = cross_val_score(svc, X_res, y_res,cv=15, n_jobs=-1, verbose=10)\n",
        "print(mean(scores))"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   12.7s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7115942028985507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaahV8thfrCd",
        "colab_type": "text"
      },
      "source": [
        "## **Submission creation for Kaggle competition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h4uw7r3fqZP",
        "colab_type": "code",
        "outputId": "f026d634-c81d-412f-b69e-c18fbd849e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating a nump list of integers from 1 - 2819 to add as header\n",
        "ID = np.arange(1,2819)\n",
        "print(ID)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1    2    3 ... 2816 2817 2818]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-NyjnU9ft3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "0a0a9045-d6de-40d0-e948-b610c3a98ce0"
      },
      "source": [
        "# Creating the pandas dataframe containing the ID values and the Prediction values\n",
        "# for Kaggle submission\n",
        "final = [int(x) for x in y_pred]\n",
        "dataset = pd.DataFrame({'ID':ID,'prediction':final})\n",
        "dataset"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2788</th>\n",
              "      <td>2789</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2789</th>\n",
              "      <td>2790</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2790</th>\n",
              "      <td>2791</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2791</th>\n",
              "      <td>2792</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2792</th>\n",
              "      <td>2793</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2793</th>\n",
              "      <td>2794</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2794</th>\n",
              "      <td>2795</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>2796</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>2797</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>2798</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>2799</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>2800</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2800</th>\n",
              "      <td>2801</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2801</th>\n",
              "      <td>2802</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2802</th>\n",
              "      <td>2803</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2803</th>\n",
              "      <td>2804</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2804</th>\n",
              "      <td>2805</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2805</th>\n",
              "      <td>2806</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2806</th>\n",
              "      <td>2807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2807</th>\n",
              "      <td>2808</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808</th>\n",
              "      <td>2809</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2809</th>\n",
              "      <td>2810</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2810</th>\n",
              "      <td>2811</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811</th>\n",
              "      <td>2812</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2812</th>\n",
              "      <td>2813</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2813</th>\n",
              "      <td>2814</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2814</th>\n",
              "      <td>2815</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2815</th>\n",
              "      <td>2816</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2816</th>\n",
              "      <td>2817</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2817</th>\n",
              "      <td>2818</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2818 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID  prediction\n",
              "0        1           1\n",
              "1        2           0\n",
              "2        3           1\n",
              "3        4           0\n",
              "4        5           0\n",
              "5        6           1\n",
              "6        7           0\n",
              "7        8           1\n",
              "8        9           1\n",
              "9       10           0\n",
              "10      11           0\n",
              "11      12           1\n",
              "12      13           1\n",
              "13      14           0\n",
              "14      15           1\n",
              "15      16           1\n",
              "16      17           0\n",
              "17      18           1\n",
              "18      19           0\n",
              "19      20           1\n",
              "20      21           0\n",
              "21      22           1\n",
              "22      23           1\n",
              "23      24           1\n",
              "24      25           0\n",
              "25      26           0\n",
              "26      27           1\n",
              "27      28           0\n",
              "28      29           1\n",
              "29      30           1\n",
              "...    ...         ...\n",
              "2788  2789           1\n",
              "2789  2790           1\n",
              "2790  2791           1\n",
              "2791  2792           1\n",
              "2792  2793           1\n",
              "2793  2794           1\n",
              "2794  2795           1\n",
              "2795  2796           1\n",
              "2796  2797           1\n",
              "2797  2798           0\n",
              "2798  2799           0\n",
              "2799  2800           1\n",
              "2800  2801           0\n",
              "2801  2802           0\n",
              "2802  2803           0\n",
              "2803  2804           1\n",
              "2804  2805           0\n",
              "2805  2806           1\n",
              "2806  2807           0\n",
              "2807  2808           0\n",
              "2808  2809           1\n",
              "2809  2810           0\n",
              "2810  2811           1\n",
              "2811  2812           1\n",
              "2812  2813           1\n",
              "2813  2814           1\n",
              "2814  2815           1\n",
              "2815  2816           0\n",
              "2816  2817           1\n",
              "2817  2818           1\n",
              "\n",
              "[2818 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gnp7gwKfwf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# e.g. save pandas output as csv\n",
        "dataset.to_csv('SVM.csv', index = False)\n",
        "\n",
        "# or any other file as usual\n",
        "# with open('example.csv', 'w') as f:\n",
        "#   f.write('your strings here')\n",
        "\n",
        "files.download('SVM.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BypOY-DtV-th",
        "colab_type": "text"
      },
      "source": [
        "## **Learning curve method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_LbsiOKUcLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting learning curve of the trained SVC classifier\n",
        "# Method found: \n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY7QK1-_xoql",
        "colab_type": "text"
      },
      "source": [
        "## **Plotting the learning curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xX5vRYuWgS3",
        "colab_type": "code",
        "outputId": "b06a2327-6574-41ec-8ba5-f1aa762d660b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plotting the learning curve of the classifier trained\n",
        "title = \"SVC Learning curve\"\n",
        "# Cross validation with 100 iterations to get smoother mean test and train\n",
        "# score curves, each time with 20% data randomly selected as a validation set.\n",
        "cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
        "\n",
        "plot_learning_curve(svc, title, X_res, y_res, ylim=(0, 1.01), cv=cv, n_jobs=-1)\n",
        "plt.savefig(\"learningcurve.png\")\n",
        "files.download(\"learningcurve.png\")\n",
        "plt.show()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njAATBcMwDCPg/wPfhnZ5aWR0BQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUgqhSN4P4zz",
        "colab_type": "text"
      },
      "source": [
        "#**SVC Model with only CNN features**\n",
        "This was an investigation of training a support vector classifier with only the CNN features. The CNN features have a high dimensionality and are very descriptive in terms of image features. These next 19 cells are an implementation of a half split classifier model only using the CNN features. The GIST feature could also be used in the same manner. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ2Idn52hvVr",
        "colab_type": "text"
      },
      "source": [
        "## **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLN23jFvP4Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of CNN features\n",
        "cnnFeatures = []\n",
        "# Seperating each feature\n",
        "for feature in X:\n",
        "  cnnFeatures.append(feature[:4096])\n",
        "X = cnnFeatures\n",
        "# Splitting the test data\n",
        "testdata = testdata[:,:4096]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ErCPwJRiB58",
        "colab_type": "text"
      },
      "source": [
        "## **Pre-processing - Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9b26EUfl6ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying standard normalization to get optimized results\n",
        "transformer = Normalizer().fit(X)\n",
        "# Normalizing the X data\n",
        "X = transformer.transform(X)\n",
        "# Normalizing the test data\n",
        "testdata = transformer.transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0SNGVgviGL0",
        "colab_type": "text"
      },
      "source": [
        "## **Undersampling the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvSdHaULQEdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_res, y_res = rus.fit_resample(X, y)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBlOUqtOiJXc",
        "colab_type": "text"
      },
      "source": [
        "## **Feature selection - PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBcrMvULQF1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying principal component analysis (PCA) to reduce the dimensionality of the training data set consisting of\n",
        "# a variation of values.\n",
        "\n",
        "pca = PCA(n_components=0.92, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(X_res)\n",
        "X_res = pca.transform(X_res)\n",
        "testdata = pca.transform(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ZCbMyficFx",
        "colab_type": "text"
      },
      "source": [
        "## **SVC classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHR6HUSYQF3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting Kernel SVM to the Training set\n",
        "svc = SVC(C=1.0, kernel='linear', gamma=0.1) \n",
        "svc.fit(X_res, y_res) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WekXrM80QF5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = svc.predict(testdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wok0TPMWiigW",
        "colab_type": "text"
      },
      "source": [
        "## **Cross validation score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2tUKAo_QF78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returning the cross validation score using KFolds. \n",
        "scores = cross_val_score(svc, X_res, y_res.ravel(),cv=5, n_jobs=-1, verbose=10)\n",
        "print(mean(scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxSlvnxdiyA4",
        "colab_type": "text"
      },
      "source": [
        "## **Preparing data for submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8N_G1JQF_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a nump list of integers from 1 - 2819\n",
        "ID = np.arange(1,2819)\n",
        "print(ID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qZF851tQGBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the pandas dataframe containing the ID values and the Prediction values\n",
        "# for Kaggle submission\n",
        "final = [int(x) for x in y_pred]\n",
        "dataset = pd.DataFrame({'ID':ID,'prediction':final})\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK5oXrsBQNYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# e.g. save pandas output as csv\n",
        "dataset.to_csv('SVMcnnundersampled.csv', index = False)\n",
        "\n",
        "# or any other file as usual\n",
        "# with open('example.csv', 'w') as f:\n",
        "#   f.write('your strings here')\n",
        "\n",
        "files.download('SVMcnnundersampled.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnTLkv_1i02I",
        "colab_type": "text"
      },
      "source": [
        "## **Plotting the learning curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4b0miCtQPXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting the learning curve of the classifier trained\n",
        "title = \"Learning Curves\"\n",
        "# Cross validation with 100 iterations to get smoother mean test and train\n",
        "# score curves, each time with 20% data randomly selected as a validation set.\n",
        "cv = ShuffleSplit(n_splits=40, test_size=0.2, random_state=0)\n",
        "plt.savefig(\"learningcurve.png\")\n",
        "files.download(\"learningcurve.png\")\n",
        "plot_learning_curve(svc, title, X_res, y_res, ylim=(0.7, 1.01), cv=cv, n_jobs=-1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}