{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Kaze.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rsgHZgWCqDW",
        "colab_type": "code",
        "outputId": "0f4c9b8c-9870-428f-82d2-8c09e690246c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np  \n",
        "from sklearn.cluster import KMeans\n",
        "from matplotlib import pyplot as plt\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh-m1gY_hfw9",
        "colab_type": "text"
      },
      "source": [
        "## **Setting up data paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NNDjrBhC-iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root path for the animal images\n",
        "root_path = \"gdrive/My Drive/Computer Vision/Coursework/JPEGImages/\" \n",
        "# Listing all the elements within the root path images\n",
        "animal_images = os.listdir(root_path)\n",
        "# Setting the training and testing data up\n",
        "training_labels = ['antelope','grizzly+bear','killer+whale','beaver','dalmatian','horse','german+shepherd','blue+whale','siamese+cat','skunk','mole','tiger','moose'\n",
        "                    ,'spider+monkey','elephant','gorilla','ox','fox','sheep','hamster','squirrel','rhinoceros','rabbit','bat','giraffe','wolf','chihuahua','weasel'\n",
        "                    ,'otter','buffalo','zebra','deer','bobcat','lion','mouse','polar+bear','collie','walrus','cow','dolphin']\n",
        "training_data = {}\n",
        "\n",
        "test_classes = ['chimpanzee','giant+panda','leopard','persian+cat','pig','hippopotamus','humpback+whale','raccoon','rat','seal']\n",
        "\n",
        "testing_data = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzhb-Ls7hkkx",
        "colab_type": "text"
      },
      "source": [
        "## **Loading the training animal images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eulMbavnDahb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,classe in enumerate(training_labels):\n",
        "  print('Processing class: ',i,classe)\n",
        "  class_paths = os.listdir(root_path+classe)\n",
        "  orb_dict3[classe] = []\n",
        "  class_paths_subsample = class_paths[int(len(class_paths))-int(len(class_paths)/3):len(class_paths)]\n",
        "  for file in class_paths_subsample:\n",
        "    if file != '.DS_Store':\n",
        "      img = cv2.imread(root_path+classe+ \"/\" +file)\n",
        "      img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "      img_resized = cv2.resize(img_RGB,None,fx=0.5,fy=0.5)\n",
        "      orb_dict3[classe].append(img_resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwbVvM983u_U",
        "colab_type": "text"
      },
      "source": [
        "## **Loading the test animal images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZa5p_uE3tUc",
        "colab_type": "code",
        "outputId": "5096e2d8-29ca-4496-f1b5-4daaa81494ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "for i,classe in enumerate(test_classes):\n",
        "  print('Processing class: ',i,classe)\n",
        "  class_paths = os.listdir(root_path+classe)\n",
        "  testing_data[classe] = []\n",
        "  #class_paths_subsample = class_paths[int(len(class_paths))-int(len(class_paths)/3):len(class_paths)]\n",
        "  for file in class_paths:\n",
        "    if file != '.DS_Store':\n",
        "      img = cv2.imread(root_path+classe+ \"/\" +file)\n",
        "      img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "      img_resized = cv2.resize(img_RGB,None,fx=0.5,fy=0.5)\n",
        "      testing_data[classe].append(img_resized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing class:  0 chimpanzee\n",
            "Processing class:  1 giant+panda\n",
            "Processing class:  2 leopard\n",
            "Processing class:  3 persian+cat\n",
            "Processing class:  4 pig\n",
            "Processing class:  5 hippopotamus\n",
            "Processing class:  6 humpback+whale\n",
            "Processing class:  7 raccoon\n",
            "Processing class:  8 rat\n",
            "Processing class:  9 seal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bopqbV9ZGJyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('orb_dict1.pickle', 'wb') as handle:\n",
        "    #pickle.dump(orb_dict1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('gdrive/My Drive/Computer Vision/Coursework/ORB/orb_dict3.pickle', 'rb') as handle1:\n",
        "   orb_dict3 = pickle.load(handle1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_QvjYD2wlkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combining all the 1/3 pickles to 1 big dictionary\n",
        "orb_train_dict = orb_dict1.copy()\n",
        "for feature in [orb_dict2,orb_dict3]:\n",
        "  for k in feature.keys():\n",
        "    for v in feature[k]:\n",
        "      orb_train_dict[k].append(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMkoiNnzvOif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('orb_train_dict.pickle', 'wb') as handle:\n",
        "    pickle.dump(orb_train_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#with open('gdrive/My Drive/Computer Vision/Coursework/ORB/orb_train_dict.pickle', 'rb') as handle1:\n",
        "   #orb_train_dict = pickle.load(handle1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmKA3bu7L9E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(orb_image_dict,animal_labels,vector_size=32):\n",
        "  orb_features = {}\n",
        "  alg = cv2.KAZE_create()\n",
        "  for i,animal in enumerate(animal_labels):\n",
        "    dsc_list = []\n",
        "    print(\"Extracting kaze features from: \", i, animal)\n",
        "    for img in orb_image_dict[animal]:\n",
        "      kps = alg.detect(img)\n",
        "      kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
        "      kps, dsc = alg.compute(img, kps)\n",
        "      dsc = dsc.flatten()\n",
        "      dsc_list.append(dsc)\n",
        "      needed_size = (vector_size * 64)\n",
        "      if dsc.size < needed_size:\n",
        "        #if we have less the 32 descriptors then just adding zeros at the\n",
        "        #end of our feature vector\n",
        "        dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)]) \n",
        "    orb_features[animal] = dsc_list\n",
        "  return orb_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDx7PksOXYRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaze_train_features = extract_features(orb_train_dict,training_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkmUGFZe3YkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaze_test_features = extract_features(testing_data,test_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqM4bwYAigHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('kaze_test_features.pickle', 'wb') as handle:\n",
        "    #pickle.dump(kaze_test_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('gdrive/My Drive/Computer Vision/Coursework/KAZE/kaze_test_features.pickle', 'rb') as handle1:\n",
        "   kaze_test_features = pickle.load(handle1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z3tvkktiPTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orb_test_features = extract_features(orb_dict,test_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xy7Os_piffE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('orb_train_features.pickle', 'wb') as handle:\n",
        "    #pickle.dump(orb_train_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('gdrive/My Drive/Computer Vision/Coursework/KAZE/kaze_train_features.pickle', 'rb') as handle1:\n",
        "   kaze_train_features = pickle.load(handle1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj4po7ZBkQEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training class\n",
        "train_class = np.loadtxt('trainclasses.txt', delimiter='\\t', usecols=[0], dtype=np.str)  \n",
        "\n",
        "#testing class\n",
        "test_class = np.loadtxt('testclasses.txt', delimiter='\\t',usecols=[0], dtype=np.str) \n",
        "\n",
        "# Reading the predicate binary text file (correlation between animal classes and its attributes)\n",
        "M = np.loadtxt('predicate-matrix-binary.txt')\n",
        "\n",
        "# Predicates within the predicate matrix. 85\n",
        "predicates = np.loadtxt('predicates.txt',delimiter='\\t',usecols=[1], dtype=np.str)\n",
        "\n",
        "#class\n",
        "classes = np.loadtxt('classes.txt', delimiter='\\t', usecols=[1], dtype=np.str)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOsUsCcyHVLT",
        "colab_type": "code",
        "outputId": "3b393f06-89ad-4d9c-9b1b-ea7ed4d3826b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(predicates)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['black' 'white' 'blue' 'brown' 'gray' 'orange' 'red' 'yellow' 'patches'\n",
            " 'spots' 'stripes' 'furry' 'hairless' 'toughskin' 'big' 'small' 'bulbous'\n",
            " 'lean' 'flippers' 'hands' 'hooves' 'pads' 'paws' 'longleg' 'longneck'\n",
            " 'tail' 'chewteeth' 'meatteeth' 'buckteeth' 'strainteeth' 'horns' 'claws'\n",
            " 'tusks' 'smelly' 'flys' 'hops' 'swims' 'tunnels' 'walks' 'fast' 'slow'\n",
            " 'strong' 'weak' 'muscle' 'bipedal' 'quadrapedal' 'active' 'inactive'\n",
            " 'nocturnal' 'hibernate' 'agility' 'fish' 'meat' 'plankton' 'vegetation'\n",
            " 'insects' 'forager' 'grazer' 'hunter' 'scavenger' 'skimmer' 'stalker'\n",
            " 'newworld' 'oldworld' 'arctic' 'coastal' 'desert' 'bush' 'plains'\n",
            " 'forest' 'fields' 'jungle' 'mountains' 'ocean' 'ground' 'water' 'tree'\n",
            " 'cave' 'fierce' 'timid' 'smart' 'group' 'solitary' 'nestspot' 'domestic']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs6DpzFckSCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_M_matrix = np.delete(M, (24,38,14,5,41,13,17,33,23,34), axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYIVv0M0kSox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing the X Value //training\n",
        "black_list = []\n",
        "for animal in train_class:\n",
        "  for feature in kaze_train_features[animal]:\n",
        "    black_list.append(feature.ravel())\n",
        "feature_matrix = np.array(black_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr1VY433FRIV",
        "colab_type": "code",
        "outputId": "72b6f6ab-8fa4-4754-c204-78925fd48fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "(feature_matrix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0377282e-02, -2.7707106e-02,  9.7728752e-02, ...,\n",
              "         1.0015958e-02,  5.9550084e-02,  2.7646190e-02],\n",
              "       [ 6.8489061e-04, -2.3811727e-03,  4.5076393e-02, ...,\n",
              "         2.0871963e-02,  6.4833976e-02,  5.2330460e-02],\n",
              "       [-1.1468822e-02, -1.6773557e-02,  2.0489164e-02, ...,\n",
              "         2.6638178e-02,  5.3928822e-02,  7.0401542e-02],\n",
              "       ...,\n",
              "       [ 3.2011986e-02,  5.4198381e-02,  6.9107287e-02, ...,\n",
              "         6.7248061e-02,  2.4781395e-02,  6.7273319e-02],\n",
              "       [-2.2639628e-03, -5.2653000e-02,  5.8395766e-02, ...,\n",
              "         2.1778759e-02,  1.3170859e-01,  1.0538381e-01],\n",
              "       [-1.6900769e-01, -1.5192108e-01,  1.6966869e-01, ...,\n",
              "         1.2277416e-04,  1.7018221e-02,  5.3344887e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjlvcH7nkYxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#minus testing classes\n",
        "train_pred_dict = {}\n",
        "column_list = []\n",
        "for i in range(0,85):\n",
        "  column_list.append(new_M_matrix[:,i])\n",
        "  train_pred_dict[predicates[i]] = column_list[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTMtloMYkaZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#all classes\n",
        "pred_map = []\n",
        "pred_dict = {}\n",
        "for i in range(0,85):\n",
        "  pred_map.append(M[:,i])\n",
        "  pred_dict[predicates[i]] = pred_map[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3NpjRJ2keyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#primary imports\n",
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Data split for pre-processing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuNI5JtgKtJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing dimensionality that doesn't conform to the matrix. (training)\n",
        "for animal,features in kaze_train_features.items():\n",
        "  for feature in features:\n",
        "    if feature.ravel().shape[0] != 2048:\n",
        "      features.remove(feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fffpbQ_dHbwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing dimensionality that doesn't conform to the matrix.\n",
        "new_kaze_train_features = {}\n",
        "for animal,features in kaze_train_features.items():\n",
        "  for feature in features:\n",
        "    if feature.ravel().shape[0] != 2048:\n",
        "      print(animal,feature.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFJw90emEd7E",
        "colab_type": "code",
        "outputId": "12a5a112-120c-47bf-8293-23a9cd9c4a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#removing dimensionality that doesn't conform to the matrix. (testing)\n",
        "for animal,features in kaze_test_features.items():\n",
        "  for feature in features:\n",
        "    if feature.ravel().shape[0] != 2048:\n",
        "      features.remove(feature)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nPKzyxBEeC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing dimensionality that doesn't conform to the matrix.\n",
        "new_kaze_train_features = {}\n",
        "for animal,features in kaze_test_features.items():\n",
        "  for feature in features:\n",
        "    if feature.ravel().shape[0] != 2048:\n",
        "      print(animal,feature.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OSHbS0qkgsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_attribute_models(features):\n",
        "  models = {}\n",
        "  for att in predicates: \n",
        "    y = []\n",
        "    att_output = train_pred_dict[att]\n",
        "    for i,animal in enumerate(training_labels):\n",
        "      if att_output[i] == 1:\n",
        "        positive = np.ones((len(kaze_train_features[animal]),1), dtype=int)\n",
        "        for pos_val in positive:\n",
        "          y.append(*pos_val)\n",
        "      else:\n",
        "        negative = np.zeros((len(kaze_train_features[animal]),1), dtype=int)\n",
        "        for neg_val in negative:\n",
        "          y.append(*neg_val)\n",
        "    y = np.array(y)\n",
        "    X = features\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.44, random_state = 42)\n",
        "    svm = LinearSVC()\n",
        "    clf = CalibratedClassifierCV(svm)\n",
        "    clf.fit(X_train,y_train)\n",
        "    print(att,\"classifier trained\")\n",
        "    score = clf.score(X_test,y_test)\n",
        "    print(\"The\",att,\"classifier score is : \",score*100)\n",
        "    models[att] = clf\n",
        "  return models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8Js0gtZtcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaze_classifiers1 = train_attribute_models(feature_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2tLDYf23IOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('kazeclf1.pickle', 'wb') as handle:\n",
        "    pickle.dump(kaze_classifiers1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#with open('gdrive/My Drive/Computer Vision/Coursework/KAZE/kazeclf.pickle', 'rb') as handle1:\n",
        "   #kazeclf = pickle.load(handle1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nJzJxnUkq1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_attribute_probs(classifiers):\n",
        "  prob_dict = {}\n",
        "  for att,clf in classifiers.items():\n",
        "    prob_list = []\n",
        "    for animal,dsc_list in kaze_test_features.items():\n",
        "      for dsc in dsc_list:\n",
        "        y_proba = clf.predict_proba([dsc])\n",
        "        prob_list.append(y_proba)\n",
        "    prob_dict[att] = prob_list\n",
        "  return prob_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jRTRubE6eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "att_prob = compute_attribute_probs(kaze_classifiers1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wexstzjGoXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('att_prob1.pickle', 'wb') as handle:\n",
        "    pickle.dump(att_prob, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#with open('gdrive/My Drive/Computer Vision/Coursework/ORB/kazeclf.pickle', 'rb') as handle1:\n",
        "   #orb_train_features = pickle.load(handle1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay9bs2wM2uqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_attribute_probs(classifiers):\n",
        "  prob_dict = {}\n",
        "  for att,clf in classifiers.items():\n",
        "    prob_list = []\n",
        "    for animal,dsc_list in kaze_test_features.items():\n",
        "      for dsc in dsc_list:\n",
        "        y_proba = clf.predict_proba([dsc])\n",
        "        prob_list.append(y_proba)\n",
        "    prob_dict[att] = prob_list\n",
        "  return prob_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YduoPBH-CMOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = compute_attribute_probs(kaze_classifiers1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68fQj1K0k2HV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dictionary which contains the key as the attributes and the value as the animal\n",
        "#outputs whether the attribute is present or not (1 or 0)\n",
        "predicate_dict = {}\n",
        "for attribute, predicates in pred_dict.items():\n",
        "  predicate_dict[attribute]= {}\n",
        "  for i,animal in enumerate(classes):\n",
        "    predicate_dict[attribute][animal] = pred_dict[attribute][i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNHqML1pk414",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#method will return a dictonary. key:test_animal_class, value: probabilities of the class being in each img\n",
        "def compute_class_probs(test_features):\n",
        "  #dictonary containing as key the test_animal_class, value as the probabilities of each class in img.\n",
        "  prob_dict = {}\n",
        "  #total probability multiplication\n",
        "  total_prob_mult = 1\n",
        "  for animal in test_features.keys():\n",
        "    total_prob_mult = 1\n",
        "    prob_list = []\n",
        "    for i in range(2455):\n",
        "      total_prob_mult = 1\n",
        "      for att in predicates:\n",
        "        if predicate_dict[att][animal] == 1:\n",
        "          total_prob_mult = total_prob_mult * probs[att][i][0][1]\n",
        "        else:\n",
        "          total_prob_mult = total_prob_mult * probs[att][i][0][0]\n",
        "      prob_list.append(total_prob_mult)\n",
        "    prob_dict[animal] = prob_list\n",
        "  return prob_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcOc1QF92k4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_prob = compute_class_probs(kaze_test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "homY0udMk-Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chimpanzee_list = ['chimpanzee'] * 200\n",
        "giantpanda_list = ['giant+panda'] * 250\n",
        "leopard_list = ['leopard'] * 200\n",
        "persiancat_list = ['persian+cat'] * 198\n",
        "pig_list = ['pig'] * 269 \n",
        "hippopotamus_list = ['hippopotamus'] * 300\n",
        "humpbackwhale_list = ['humpback+whale'] * 287\n",
        "raccoon_list = ['raccoon'] * 200\n",
        "rat_list = ['rat'] * 251\n",
        "seal_list = ['seal'] * 300\n",
        "animal_list = []\n",
        "animal_list.extend(chimpanzee_list)\n",
        "animal_list.extend(giantpanda_list)\n",
        "animal_list.extend(leopard_list)\n",
        "animal_list.extend(persiancat_list)\n",
        "animal_list.extend(pig_list)\n",
        "animal_list.extend(hippopotamus_list)\n",
        "animal_list.extend(humpbackwhale_list)\n",
        "animal_list.extend(raccoon_list)\n",
        "animal_list.extend(rat_list)\n",
        "animal_list.extend(seal_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thz1FXkjlDbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outputs a single real number denoting the overall accuracy of your system, averaged\n",
        "# over the Ntest test images.\n",
        "def compute_accuracy(test_classes):\n",
        "  prob_dict = {}\n",
        "  max_dict = {}\n",
        "  counter = 0\n",
        "  for i in range(2455):\n",
        "    prob_dict = {}\n",
        "    for animal in test_classes:\n",
        "      prob_dict[animal] = pre_prob[animal][i]\n",
        "    if max(prob_dict, key = lambda k: prob_dict[k]) == animal_list[i]:\n",
        "      counter += 1\n",
        "  result = (counter/2455) * 100\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRyfw-3P2lV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = compute_accuracy(pre_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "437tOfwcLl_s",
        "colab_type": "code",
        "outputId": "ed268c27-3f18-41d7-f435-952f3d0a6343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.386965376782078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}